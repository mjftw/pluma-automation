import datetime
from pluma.test.testbase import TestBase
from typing import Dict, Iterable, List, Optional, Sequence
from pluma.core.baseclasses.reporterbase import ReporterBase
from pluma.reporting.xrayhelper import JiraXrayHelper, JiraResult, JiraTestPlanIssue
from pluma.core.baseclasses.logging import Logger

# TODO: store test XRAY IDs so we don't have to search for them every time we update them.
# In addition, we should really only be pushing updates to the tests that changed.
# TODO: Figure out what test metadata we have and what we need to generate. In addition,
# figure out where this reporter should hook into the TestRunner/TestController, and how
# that metadata is going to get piped.
# TODO: It might make more sense to implement this integration using the XRay GraphQL API,
# seeing as we are performing a lot searching.
# TODO: XRay steps depending on the structure of each test?

PLUMA_PLAN_TITLE = "Pluma autogenerated test plan"
PLUMA_EXEC_SUMMARY_PREFIX = "Pluma autogenerated test execution starting at "

log = Logger()


class XRayReporter(ReporterBase):
    def __init__(
        self,
        jira_project_key: str,
        jira_project_url: str,
        xray_credentials_client_id: str,
        xray_credentials_client_secret: str,
        jira_credentials_username: str,
        jira_credentials_password: str,
        test_plan_name: str
    ):
        self.test_plan_name = test_plan_name
        self._xray_helper = JiraXrayHelper(
            project_key=jira_project_key,
            jira_url=jira_project_url,
            xray_client_id=xray_credentials_client_id,
            xray_client_secret=xray_credentials_client_secret,
            jira_user=jira_credentials_username,
            jira_password=jira_credentials_password
        )
        self._clear_state()

    def _clear_state(self):
        self._running_plan: Optional[JiraTestPlanIssue] = None
        self._running_execution_key: Optional[str] = None
        self._running_execution_metadata: Dict[str, str] = {}
        self._running_execution_test_metadata: List[JiraResult] = []

    def _push_running_execution_plan_to_xray(self):
        # create a test execution on that test plan
        self._running_execution_key = self._xray_helper.create_or_update_test_execution(
            self._running_plan,
            self._running_execution_metadata,
            self._running_execution_test_metadata
        )

    def _pluma_test_to_jira_test(self, test: TestBase, start_time: datetime.datetime, end_time: Optional[datetime.datetime] = None) -> JiraResult:
        return JiraResult(
            name=test._test_name,
            status='TODO',
            startDate=start_time,
            stopDate=end_time if end_time else start_time + datetime.timedelta(1),
        )

    def _get_running_test_meta(self, test: TestBase) -> Optional[JiraResult]:
        for test_meta in self._running_execution_test_metadata:
            if test_meta.name == str(test):
                return test_meta

    def report_session_start(self, time: datetime.datetime, session: Sequence[TestBase]):
        # create a test plan (or update one that exists)
        self._running_plan = self._xray_helper.create_or_update_plan(
            self.test_plan_name, PLUMA_PLAN_TITLE)
        if self._running_plan is None:
            raise RuntimeError(
                'Unable to create or update the XRay test plan, check your credentials.')
        # generate XRay metadata for each test
        self._running_execution_test_metadata = [
            self._pluma_test_to_jira_test(test, time) for test in session]

        # generate XRay metadata for the plan
        start_time_str = JiraXrayHelper.date_to_xray_format(time)
        end_time_str = JiraXrayHelper.date_to_xray_format(time + datetime.timedelta(1))
        self._running_execution_metadata = {
            "summary": f"{PLUMA_EXEC_SUMMARY_PREFIX} {start_time_str}",
            "startDate": start_time_str,
            # Guess the end date? Apparently it's a "predicted" value
            "endDate": end_time_str,
        }
        # create a test execution on that test plan
        self._push_running_execution_plan_to_xray()

    def report_session_end(self, time: datetime.datetime, session):
        # Update the test execution with the final end time
        self._running_execution_metadata["endDate"] = JiraXrayHelper.date_to_xray_format(time)
        self._xray_helper.create_or_update_test_execution(
            self._running_plan,
            self._running_execution_metadata,
            self._running_execution_test_metadata,
        )
        # clear state
        self._clear_state()

    def report_test_start(self, time: datetime.datetime, session, test: TestBase):
        # match the test being started with the test metadata object
        running_test_meta = self._get_running_test_meta(test)
        if running_test_meta is None:
            log.warning(
                f'Xray reporter got an unrecognized test name {test} on report_test_start hook, not reporting it.')
            return
        # update the test metadata object with the new status
        running_test_meta.status = 'EXECUTING'
        # push this update to the xray test execution
        self._push_running_execution_plan_to_xray()

    def report_test_end(self, time: datetime.datetime, session: Sequence[TestBase], test: TestBase, result_passed: bool, result_message: str):
        # match the test being started with the test metadata object
        running_test_meta = self._get_running_test_meta(test)
        if running_test_meta is None:
            log.warning(
                f'Xray reporter got an unrecognized test name {test} on report_test_start hook, not reporting it.')
            return
        # update the test metadata object with the new status
        running_test_meta.status = 'PASSED' if result_passed else 'FAILED'
        running_test_meta.summary = result_message
        # push this update to the xray test execution
        self._push_running_execution_plan_to_xray()
